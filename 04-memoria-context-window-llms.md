# Memória de Trabalho e Context Window em LLMs

Na Neurociência, a **memória de trabalho** é a capacidade de manter e manipular informações temporárias para realizar tarefas cognitivas complexas, como raciocínio, compreensão de linguagem e tomada de decisão. É limitada em duração e quantidade, mas essencial para o pensamento humano.

## Conexão com IA
Nos modelos de linguagem (LLMs), existe um conceito equivalente chamado **context window**.  
Ele define quantos tokens (palavras ou pedaços de texto) o modelo consegue "lembrar" durante uma interação. Assim como a memória de trabalho humana, essa janela é limitada e influencia diretamente a qualidade das respostas.

- **Memória de trabalho biológica** → mantém informações temporárias para raciocínio.  
- **Context window artificial** → armazena tokens temporários para gerar respostas coerentes.  

## Exemplos práticos
- **Chatbots**: precisam de janelas maiores para manter o contexto em diálogos longos.  
- **Documentos extensos**: modelos com context window ampliado conseguem analisar textos maiores sem perder informações.  
- **Engenharia de prompt**: estruturar instruções de forma clara ajuda a otimizar o uso da janela de contexto.  

## Impacto
A analogia entre memória de trabalho e context window mostra como IA e Neurociência se aproximam:
- Limitações cognitivas humanas inspiram restrições técnicas em modelos.  
- Estratégias de atenção e organização melhoram desempenho em ambos os casos.  
- Avanços em LLMs buscam expandir context windows, aproximando ainda mais da capacidade humana de lidar com grandes volumes de informação.  

---

*Escrito por Thais Ines. Este artigo faz parte da série sobre como conceitos da Neurociência inspiram e fortalecem a Inteligência Artificial.*
