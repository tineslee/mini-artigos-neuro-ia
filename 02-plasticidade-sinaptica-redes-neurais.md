# Plasticidade Sináptica e Redes Neurais Artificiais

Na Neurociência, a **plasticidade sináptica** é a capacidade do cérebro de modificar conexões entre neurônios com base em experiências. Esse mecanismo é fundamental para o aprendizado humano: quanto mais uma conexão é ativada, mais forte ela se torna.

## Conexão com IA
As **redes neurais artificiais** foram inspiradas nesse princípio. Cada "neurônio" artificial possui **pesos** que representam a força da conexão. Durante o treinamento, esses pesos são ajustados para que a rede aprenda padrões nos dados.

- **Plasticidade biológica** → fortalecimento ou enfraquecimento de sinapses.  
- **Plasticidade artificial** → ajuste de pesos em redes neurais.  

## Exemplos práticos
- **Backpropagation**: algoritmo que ajusta os pesos da rede, inspirado na ideia de reforço e correção de conexões.  
- **Deep Learning**: múltiplas camadas simulam níveis de processamento, como ocorre em áreas diferentes do cérebro.  
- **Aprendizado por reforço**: semelhante ao papel da dopamina em recompensas, ajustando conexões para maximizar resultados.

## Impacto
A plasticidade sináptica mostra que aprendizado é um processo dinâmico e contínuo.  
Na IA, esse conceito permite:
- Treinar modelos cada vez mais precisos.  
- Adaptar sistemas a novos dados.  
- Criar algoritmos que simulam a capacidade humana de aprender com experiência.

---

*Escrito por Thais Ines. Este artigo faz parte da série sobre como conceitos da Neurociência inspiram e fortalecem a Inteligência Artificial.*
